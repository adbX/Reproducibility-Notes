\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{placeins}
%\usepackage[T1]{fontenc}
\usepackage[margin=1in]{geometry}
\usepackage{etoolbox}
\usepackage{xifthen}
\usepackage{ltablex, multirow, makecell, booktabs, caption}
\usepackage[hidelinks]{hyperref}
\usepackage{xcolor}
\hypersetup{
	colorlinks,
	linkcolor={red!50!black},
	citecolor={blue!50!black},
	urlcolor={blue!80!black}
}
%\usepackage{imakeidx}
\usepackage{makeidx}
\makeindex
\usepackage[nottoc]{tocbibind}
\usepackage[style=ieee,indexing,backref]{biblatex}
\addbibresource{main.bib}
\usepackage{aas_macros}
\usepackage[toc]{glossaries}
\makeglossaries

\newglossaryentry{read}{
	name=Read,
	description={Indicates a source I need to read}
}

\newglossaryentry{categorize}{
	name=Categorize,
	description={Indicates a source I need to categorize}
}

\newglossaryentry{complete}{
	name=Complete,
	description={Indicates a section I need to complete}
}

\newglossaryentry{needcite}{
	name={Needs Citation},
	description={Indicates a claim or which I need to find a citation}
}

\newglossaryentry{expand}{
	name={Expand},
	description={Indicates a bit of information or part of a section which needs expansion to its own section}
}

\newglossaryentry{readmore}{
	name={Read More},
	description={Indicates a citation which I read parts of but which I may need to read more.}
}

\newcommand{\Read}{
	\gls{read}
}

\newcommand{\categorize}{
	\gls{categorize}
}

\newcommand{\complete}{
	\gls{complete}
}

\newcommand{\needcite}{
	\gls{needcite}
}

\newcommand{\expand}{
	\gls{expand}
}

\newcommand{\readmore}{
	\gls{readmore}
}

\newcommand{\ifempty}[3]{%
	\ifthenelse{\isempty{#1}}{#2}{#3}%
}

%\DeclareCiteCommand{\cite}
%  {\bibopenbracket\usebibmacro{prenote}}
%  {\usebibmacro{citeindex}%
%   \printtext[bibhyperref]{\usebibmacro{cite}}}
%  {\multicitedelim}
%  {\usebibmacro{postnote}\bibclosebracket}
%
%\DeclareCiteCommand*{\cite}
%  {\bibopenbracket\usebibmacro{prenote}}
%  {\usebibmacro{citeindex}%
%   \printtext[bibhyperref]{\usebibmacro{citeyear}}}
%  {\multicitedelim}
%  {\usebibmacro{postnote}\bibclosebracket}
%
%\DeclareCiteCommand{\parencite}[\mkbibparens]
%  {\usebibmacro{prenote}}
%  {\usebibmacro{citeindex}%
%    \printtext[bibhyperref]{\usebibmacro{cite}}}
%  {\multicitedelim}
%  {\usebibmacro{postnote}}
%
%\DeclareCiteCommand*{\parencite}[\mkbibparens]
%  {\usebibmacro{prenote}}
%  {\usebibmacro{citeindex}%
%    \printtext[bibhyperref]{\usebibmacro{citeyear}}}
%  {\multicitedelim}
%  {\usebibmacro{postnote}}
%
%\DeclareCiteCommand{\footcite}[\mkbibfootnote]
%  {\usebibmacro{prenote}}
%  {\usebibmacro{citeindex}%
%  \printtext[bibhyperref]{ \usebibmacro{cite}}}
%  {\multicitedelim}
%  {\usebibmacro{postnote}}
%
%\DeclareCiteCommand{\footcitetext}[\mkbibfootnotetext]
%  {\usebibmacro{prenote}}
%  {\usebibmacro{citeindex}%
%   \printtext[bibhyperref]{\usebibmacro{cite}}}
%  {\multicitedelim}
%  {\usebibmacro{postnote}}
%
%\DeclareCiteCommand{\textcite}
%  {\boolfalse{cbx:parens}}
%  {\usebibmacro{citeindex}%
%   \printtext[bibhyperref]{\usebibmacro{textcite}}}
%  {\ifbool{cbx:parens}
%     {\bibcloseparen\global\boolfalse{cbx:parens}}
%     {}%
%   \multicitedelim}
%  {\usebibmacro{textcite:postnote}}

\DeclareCiteCommand{\citejournalorbooktitle}
  {\usebibmacro{prenote}}
  {\usebibmacro{citeindex}%
    \iffieldundef{journaltitle}{\usebibmacro{booktitle}}{\usebibmacro{journal}}}
  {\multicitedelim}
  {\usebibmacro{postnote}}

\newenvironment{refdef}[2] {
	\noindent \textbf{\citetitle{#1}} \cite{#1}\\ \citejournalorbooktitle{#1} \textit{(\citeyear{#1})}\\ \texttt{#2} \vspace{0.2in} \par 
} {
\vspace{0.2in}
}

\title{Research Notes}
\author{Matthew Krafczyk}
\date{\today}

\begin{document}

\maketitle

\tableofcontents

\section{Introduction}

These are my research notes while working at NCSA.

\complete

\section{Reproducibility Terms}

I will be using the ACM terms for reproducibility \cite{acm-badging}. In order of increasing strength or rigor they are:

\begin{itemize}
\item \textbf{Repeatability}: When a research team can get the same conclusions using the same experimental methods as previous
\item \textbf{Replicability}: When a separate research team can get the same conclusions using the same experimental methods as previous
\item \textbf{Reproducibility}: When a separate research team can get the same conclusions using a different experimental method as previous
\end{itemize}

There is some contention about these terms, I believe the biology people use different terms. \needcite

\section{Reproducibility Issues}

Here I'm trying to collect all the different issues which exist with reproducibility. I'm using it as a space to make sense of these issues as well as collect the references which make the case.

\complete

\subsection{Sociological Issues}

\begin{itemize}
\item Scrutinization
\item Competitive Advantage
\item Licensing
\item Monolithic codebases
\item Dirty code
\item \textbf{Some seem \textit{strange} given the published article}
\end{itemize}

\complete

\subsection{Software Issues}

\begin{itemize}
\item Numerical error
\item Transparent machine software/hardware failures
\item Hard-coded machine topologies
\item \textbf{Some of these are \textit{unavoidable}}
\end{itemize}

\complete

\subsection{Hardware Issues}

\begin{itemize}
\item Special hardware requirements
\item Silent Failures
\item \textbf{Some of these are \textit{unavoidable}}
\end{itemize}

\complete

\subsubsection{Specialized Hardware}

Here I'm detailing various specialized hardware I hear about which might hamper reproducibility efforts.

\begin{itemize}
\item Large Supercomputer (for large computing runs)
\item GPUs (Usually not hard to get, but still an obstacle)
\item FPGA
\item Neuromorphic Chips \cite{neuromorphic-chips-webarticle}
\end{itemize}

\complete

\subsubsection{Handling specialized hardware}

Results run on specialized hardware should still be replicable as long as an appropriate virtual machine or emulator is available for that architecture.

\complete

\subsection{Compatibility Issues}

DOES THIS SUBSECTION DESERVE ITS OWN SECTION??

Study compatibility is a serious problem which prevents the comparison of scientific studies when researchers do not agree on input formatting, output formatting, and general scientific workflow. Without this compatibility, major work must be done to allow apples to apples comparisons between scientific works.

To make matters worse, allowing scientists to steal a method from another scientist and use it in their IDE is currently impossible due to incompatibilities inherent in each application's assuredly divergent development lines. Thus solving the compatibility will be a great step forward towards allowing the three currently difficult workflows.

\complete

\section{Causation of Reproducibility problems}

This section summarizes why reproducibility is a problem in various fields and not other.
\complete

\section{Numerical Precision Issues}

This section summarizes issues related to numerical precisions. Whether it's an algorithm touted to be more precise, or a tool to optimize a program it will be found here.

\complete

\subsection{Scientific Problems needing special precision}

A number of problems need special scientific precision. David Bailey did a great job laying this out\cite{high-precision-arith-in-science,dhb-zurich-hp}. I reproduce his table from \cite{dhb-zurich-hp} as Table \ref{tab:precision} to give an idea of the gamut.

\FloatBarrier
\begin{table}[t]
\caption{Typical bit precision necessary for various scientific fields}\label{tab:precision}
\begin{tabular}{lr}
Problem Type & Number of bits(?) necessary \\
Planetary orbit calculations & 32 \\
Climate modeling & 32 \\
Optimization problems in biology and other fields & 32\\
Schrodinger solutions for lithium and helium atoms & 32\\
Scattering amplitudes of fundamental particles & 32\\
Discrete dynamical systems & 32\\
Supernova simulations & 32-64 \\
Coulomb n-body atomic system simulations & 32-120\\
Electromagnetic scattering theory & 32-100\\
The Taylor algorithm for ODEs & 100-600\\
Ising integrals from mathematical physics & 100-1,000\\
Problems in experimental mathematics & 100-50,000\\
\end{tabular}
\end{table}
\FloatBarrier

\subsection{Solutions to reduction error issues}

Two techniques which can be used to solve reduction error are to either enforce an ordering to the summation. This can be done by creating a unique id for each element of the sum, and guarenteeing that these ids are identical each run and making sure that the summation sums the id'd elements the same way each time. Another is to use the technique outlined here: \cite{repro-fast-sum}.

\subsection{Program Precision Optimizers}

These tools analyze a program's operation in some way and produce recommendations about data types or run conditions which will preserve or increase a programs precision while also improving a programs performance.

\begin{itemize}
\item BLAME Analysis \cite{blame-analysis}
\item PRECIMONIOUS \needcite
\end{itemize}

\subsubsection{BLAME Analysis}

This tool is created from LLVM and analyzes code passed through it for operations which can be run at reduced precision. \cite{blame-analysis}

\complete?

\section{Goals for reproducibility}

I want to make the following methods more easily executable. Replicability and Compatibility will be huge steps towards making this happen.

\complete

\subsection{Method Appropriation}

\begin{enumerate}
\item \textbf{A} is working on airfoil using method \boldmath$\alpha$, but sim has a problem
\item \textbf{B} publishes method $\beta$ which claims to fix said problem
\item \textbf{A} reads \textbf{B}'s paper
\item \textbf{A} downloads \textbf{B}'s materials, verifies the result
\item \textbf{A} then uses method $\beta$ to solve their problem
\item \textbf{A} publishes their airfoil citing \textbf{B} as simulation method
\end{enumerate}

\subsection{Method Tweaking}

\begin{enumerate}
\item \textbf{A} needs to simulate a large protein to find binding sites
\item \textbf{A} finds method \boldmath$\beta$ by \textbf{B} for simulating large proteins efficiently, but doesn't find binding sites.
\item \textbf{A} download's \textbf{B}'s materials, verifies the result
\item \textbf{A} adds code to find binding sites to $\beta$ producing method $\alpha$
\item \textbf{A} publishes method $\alpha$ citing \textbf{B}'s method $\beta$.
\end{enumerate}

\subsection{Method Improvement}

\begin{enumerate}
\item Performing lattice QCD, \textbf{A} finds method \boldmath$\beta$ by \textbf{B}.
\item \textbf{A} spots mistake in method $\beta$ from article
\item \textbf{A} downloads \textbf{B}'s materials, verifies the result
\item \textbf{A} changes $\beta$ creating method $\alpha$ solving mistake
\item \textbf{A} runs method $\alpha$ verifying better agreement with experimentally measured values
\item \textbf{A} publishes $\alpha$ citing \textbf{B} about this change
\end{enumerate}

\section{Empiricle Reproducibility Studies}

Here I'm collecting a list of all empirical studies about reproducibility in the scientific community. These are good places to grab statistics to show people how bad the whole situation really is. I'm collecting their timeframe, and what field they cover.

\complete

\FloatBarrier

\begin{table}[t]
\centering
\begin{tabularx}{\textwidth}{lXllX}
\caption{A list of replicability and reproducibility studies and what they say} \label{tab:replicability-studies} \\
\toprule
Citation & Title & Timeframe & Field & Results \\
\midrule
\endfirsthead
\multicolumn{5}{c}{Table \thetable\enspace (continued)} \\
\toprule
Citation & Title & Timeframe & Field & Results \\
\midrule
\endhead
\bottomrule
\multicolumn{5}{l}{Table \thetable To be continued}
\endfoot
\bottomrule
\endlastfoot
\cite{doi:10.1093/aje/kwj093} & \citetitle{doi:10.1093/aje/kwj093} & 2005 & Epidemiology & \multicolumn{1}{l}{\multirowcell{2}{93\% of articles do not detail data processing. \\ 84\% of articles did not release data.}} \\
\cite{economics-replicability-fed} & \citetitle{economics-replicability-fed} & 2015 & Economics & \multicolumn{1}{l}{\multirowcell{2}{22/67 (33\%) replicated without author contact \\ \noindent 29/59 (49\%) replicated with author contact}} \\
\bottomrule
\end{tabularx}
\end{table}

\FloatBarrier

\section{Reproducibility Software}

Here I'm collecting a list of all reproducibility software I have encountered. I'll discuss each in turn hitting what they offer and what they lack. Any specific system which doesn't have it's own section means I haven't tried it or don't know enough about it to say anything.

\complete

\subsection{Containers}

These techniques utilize a namespacing system to allow native execution of code and virtualization of OS without the need for a hypervisor.

\begin{itemize}
\item Docker \needcite
\item Vagrant \needcite
\item Signularity \needcite
\end{itemize}

\complete

\subsection{Virtual Machines}

These techniques use a hypervisor to run a logically separate virtual machine on a host machine. These tend to be slower, but as hardware vendors add support for virtualization technology to their chipsets they are getting closer to native performance.

\begin{itemize}
\item VMWare \needcite
\item Virtual Box \needcite
\item KVM \needcite
\end{itemize}

\complete

\subsection{Workflow Managers}

These softwares purport to handle all of our scientific workflow needs. They handle your source code, build your application, run it and compile the paper from the results produced. Some workflows may not fit, but they are working hard to make sure that it doesn't stay that way.

\begin{itemize}
\item Popper \Read \categorize \needcite
\item WholeTale \Read \categorize \needcite
\item CodeOcean \Read \categorize \needcite
\end{itemize}

\complete

\subsection{Workflow Analyzers}

These software tools glean information about the provenance of computations by analyzing either software meta data or software running on a system.

\begin{itemize}
\item FRAPpuccino \cite{FRAPpuccino} \Read \categorize
\item Why-Diff \cite{computational-meta-data} \Read \categorize
\item YesWorkflow \cite{computational-meta-data} \Read \categorize
\item NoWorkflow \cite{computational-meta-data} \Read \categorize
\end{itemize}

\complete

\subsection{Watchers}

These programs use a system like \texttt{strace} to track what the researcher is doing and store it in a container. This container an then in-principle be used on any other machine.

\begin{itemize}
\item ReproZip \cite{reprozip} \Read \categorize
\end{itemize}

\complete

\subsubsection{In-Practice}

The only one of these schemes which I've tried so far is ReproZip \cite{reprozip}. I ran a simple \texttt{htop} command on my laptop and tried to run it on the campus cluster where \texttt{htop} doesn't exist. This failed, but I didn't record the error that occured.

\complete

\subsection{Advanced Package and Environment Management}

These programs take control of the execution environment while also staying out of the way by using existing mechanisms to do their magic. For example, using \texttt{LD\_LIBRARY\_PATH} or \texttt{RUNPATH} instead of more complex stuff like userspace namespacing like what containers do.

\begin{itemize}
\item Spack \cite{Spack}
\item Nix \needcite \expand
\item Hashdist \needcite \expand
\end{itemize}

\subsubsection{Spack}

Spack \cite{Spack} is the only one I've tried so far. It's the best by far.

\complete

\subsection{Generalized systems}

\begin{itemize}
\item Reproducible-builds.org \cite{reproducible-builds} \Read \expand
\item Sciunits \cite{sciunits} \Read \expand
\end{itemize}

\complete

\section{Software/Data Repositories}

This is a list of the various code and data repositories which currently exist and are trying to solve some part of the replicability problem.

\begin{itemize}
\item Computer Physics Communications \cite{computer-physics-communications} \Read \expand
\item DARPA Open Catalog \cite{darpa-open-catalog} \Read \expand
\item DOE Code \cite{doe-code} \Read \expand
\item Mendeley \cite{elsevier-mendeley-computer-physics-communication} \Read \expand
\end{itemize}

\complete

\section{Policy Efforts}

\begin{itemize}
\item \textit{Science} efforts to get researchers to publish code and data. \needcite
\item \textit{SC'XY} Conference has programs like the student cluster competition. \cite{sighpc-connect-repro-1,sighpc-connect-repro-2}
\item The ACM has started offering badges for articles which are replicated or reproduced \cite{acm-badging-announcement}.
\end{itemize}

\complete

\section{Community Direction}

This section describes people's opinion of the community and where it is going.

\complete

\section{Statistical Tests}

This section outlines a few statistical tests which we have used in our analysis.

\subsection{Wilcoxon Ranked Sum Test}

This test was used in our first JCP paper to test whether the informed and uninformed groups were behaving in a statistically different way. \cite{doi:10.1080/01621459.1972.10481279,R-wilcoxion-test}

\subsection{Pearson's Chi-squared test for count data}

This test was used in our first JCP paper to test the difference between the informed and uninformed groups. \cite{10.2307/2984263,R-pearson-chisquare}.

\section{Notable Authors}

Here I collect together sources from notable authors in the field. I also try to summarize their contributions. Their ideas should be commonly cited in the field, or they should have multiple publications which have done some good work making clear the state of the field.

\complete

\subsection{Ioannidis}

\complete

\subsection{Victoria Stodden}

\complete

\subsection{Claerbout}

\complete

\subsection{Donoho}

\complete

\subsection{David H. Bailey}

David Bailey concerns himself with numerical precision issues. He has produced a nice summary of scientific problems which require greater than normal precision \cite{high-precision-arith-in-science,dhb-zurich-hp}. He has also been involved in the creation of tools to help find parts of a program which can be run at lower precision ostensibly to limit program execution time\cite{blame-analysis}. He has also created the mpfun library for thread-safe arbitrary precision arithmetic\cite{mpfun}.

He hosts his website\cite{david-bailey-site} which contains all of his papers, talks, and links to code and projects that he works on.

\complete

\section{Reference Descriptions}

Here I collect together the references I've encountered and read at least some of. I also include a small explanation for each reference. If available, I also break it down by subject.

\complete

\subsection{Replicability and Reproducibility Studies}

\begin{refdef}{doi:10.1093/aje/kwj093}{kwj093.pdf}
This paper describes the types of papers published in 2005 in the `American Journal of Epidemiology' and the `Journal of the American Medical Association'. I.e. what kind of study they were, did they use code, and whether that code was available. They find that 93\% of articles which required data processing did not discuss this processing. 84\% of articles which produced original studies did not report that the data produced was available. \Read
\end{refdef}

\begin{refdef}{economics-replicability-fed}{2015083pap.pdf}
This paper describes the state of replicability in Economics literature as of 2015. 22/67 (33\%) of papers are replicated without contacting the authors, 29/59 (49\%) are replicated by contacting the authors. \Read
\end{refdef}

\subsection{Numerical Issues}

\begin{refdef}{high-precision-arith-in-science}{high-prec-arith.pdf}
This paper describes different scientific tasks that require greater than 64-bits of precision. Some fields require hundreds or thousands of digits of precision for their results to be meaningful. \readmore
\end{refdef}

\begin{refdef}{dhb-zurich-hp}{dhb-zurich-hp.pdf}
This is an invited talk summarizing most of David Bailey's work. This centers around numerical precision and applications which need lots of precision. \readmore
\end{refdef}

\subsection{Reproducibility}

\begin{refdef}{repro-fast-sum}{ARITH21\_Fast\_Sum.pdf}
An algorithm for reproducible parallel summation of floating point numbers with varying accuracy and efficiency.
\end{refdef}


\begin{refdef}{collberg2014measuring}{tr.pdf}
A fun article discussing attempts to get source code and build the code. No attempts to run and reproduce the result were made.
\end{refdef}

\begin{refdef}{stodden-reproducibility-crisis}{Stodden\_Reproducibility\_Crisis.pdf}
One of Victoria's articles where she and her collaborators describe the problem of computational reproducibility. They are also plugging their own Matlab reproducibility environments. This is also another mention of Jon Claerbout and really reproducible research.
\end{refdef}

\begin{refdef}{problem-of-reproducibility}{The\_Problem\_of\_Reproducibility.pdf}
Ince describes some of the issues with reproducibility
\end{refdef}

\begin{refdef}{classification-of-methodologies-large-scale}{RR-6859.pdf}
The authors describe some different methodologies in running computational 'experiments'. This includes the classification of hardware and software environments.
\end{refdef}

\begin{refdef}{quantifying-reproducibility-computational-biology}{journal.pone.0080278.pdf}
Establishes the idea of the reproducibility score which quantifies the cost of reproducing the result in the event that details are left out of publications. Gives a nice in depth review of making a computational biology paper reproducible. Much like what I plan with the Vertical study
\end{refdef}

\begin{refdef}{collaborative-reproducibility}{1-s2.0-S0306437916300813-main.pdf}
A nice short paper describing a system where people create 'reproducibility papers' and report the existence of tools for making environments and libraries and what not available for researchers to use.
\end{refdef}

\begin{refdef}{tools-and-techniques-computational-reproducibility}{ToolsAndTechniquesComputationalReproducibilityPicollo2016.pdf}
This paper details several techniques that can be helpful to automate the reproduction of results including things like scripts and using docker containers to create virtualized environments.
\end{refdef}

\begin{refdef}{repeatability-microarray-gene-expression}{ng.295.pdf}
The researchers attempt to reproduce a bunch of microarray gene expression papers. These reproductions were limited by the availability of data and in some cases code.
\end{refdef}

\begin{refdef}{fmri-false-positives}{PNAS-2016-Eklund-7900-5.pdf}
The authors discuss how fMRI systems have huge false positive rates which is related to the existence of the dead salmon poster: Bennett-Salmon-2009.pdf
\end{refdef}

\begin{refdef}{reproducibility-computational-biology}{WhereNextForComputationalBiology.pdf}
This paper puts up a set of recommendataions for computational biology to facilitate reproducibility. Nothing that new.
\end{refdef}

\begin{refdef}{Thain-CMS-Repro}{repro-tr-2016.pdf}
An interesting paper which discusses efforts to make a CMS ROOT workflow reproducible.
\end{refdef}

\begin{refdef}{ContainersNature}{546173a.pdf}
A paper discussing Containers and how they are taking over the world
\end{refdef}

\begin{refdef}{10.1371/journal.pone.0038234}{journal.pone.0038234.pdf}
A great paper talking about scientific output differences between operating systems
\end{refdef}

\subsection{Benchmarking}

\begin{refdef}{scientific-benchmarking-parallel-computing-1}{a73-hoefler.pdf}
This paper discusses a number of problems with current benchmarking practices in the HPC community. They present their own library for HPC benchmarking as a solution to this problem.
\end{refdef}

\begin{refdef}{gropp-mpi2}{1-s2.0-0167819196000245-main.pdf}
One of the founding papers of MPI, showing how MPI has been able to create a message passing system which can achieve high performance even compared to vendor specific implementations on a variety of systems.
\end{refdef}

\begin{refdef}{gropp-parallel-io}{International Journal of High Performance Computing Applications-1998-Thakur....}
Goes into the problem of data throughput in HPC.
\end{refdef}

\begin{refdef}{gropp-test-suite}{1-s2.0-S0167819109000143-main.pdf}
This is a more detailed article about MPI benchmarking. Specifically, this paper deals with threading performance, and the challenges therein.
\end{refdef}

\begin{refdef}{gropp-mpi-repro-perf}{mpptest.pdf}
Describes a number of problems associated with testing parallel message passing implementations. Describes their test suite and how they get around these problems.
\end{refdef}

\subsection{Policy Efforts}

\begin{refdef}{acm-badging-announcement}{p5-boisvert.pdf}
Defines the 'Results Replicated' and the 'Results Reproduced' badges for the ACM. \readmore
\end{refdef}

\begin{refdef}{sighpc-connect-repro-1}{CONNECT\_14\_Oct2016.pdf}
Newsletter describing the student cluster competition at SC16. \readmore
\end{refdef}

\begin{refdef}{sighpc-connect-repro-2}{CONNECT\_15\_Feb2017.pdf}
Newsletter describing the winner of the reproducibility initiative at SC16 and the paper for the student cluster competition for SC17. \readmore
\end{refdef}

\subsection{Reproducibility Benchmarking}

\begin{refdef}{reproducibility-benchmark-dft}{aad3000.full.pdf}
%Science (2016)
A very detailed study in which a set of DFT codes had their reproducibility benchmarked. The developers and researchers for these codes got together and decided on a figure of merit to quantify their reproducibility.
\end{refdef}


\subsection{Uncertainty Quantification}

\begin{refdef}{Wilke2013}{chp\%3A10.1007\%2F978-3-642-40047-6\_7.pdf}
\end{refdef}

\subsection{Sources of Variation}

\begin{refdef}{doi:10.1093/molbev/mss136}{mss136.pdf}
A discusion of analysis methods in biology used to create a narrative for specific genes and whatnot. That non-reproducibility can so easily affect the result of analysis is the main point of this paper. Not about the reproducibility crisis in biology...
\end{refdef}

\begin{refdef}{FokkensPostmaPedersen}{P13-1166.pdf}
This paper dicusses attempts to replicate results from word similarity programs. They discuss several sources which can be sources of error
\end{refdef}

\begin{refdef}{sacks1989}{euclid.ss.1177012413.pdf}
An old paper describing a system for studying variation of computational simulations given different initial conditions and assuming deterministic simulations. This is a good starting point for my vertical research!
\end{refdef}

\begin{refdef}{DEPEND-Resiliance}{07266835.pdf}
This paper describes the DEPEND team's tool LogDiver and their work studying errors which programs encounter on large supercomputers.
\end{refdef}

\subsection{Software Quality}

\begin{refdef}{Flouri031500}{031500.full.pdf}
This paper discusses the existence of bugs in implementations of global alignment algorithms
\end{refdef}

\begin{refdef}{Darriba031930}{031930.full.pdf}
This paper discusses the code quality of several bioinformatics tools which are used in academia They find some problems and propose some practices for the scientific community.
\end{refdef}

\begin{refdef}{hattoicalepcs2011}{Hatton\_ICALEPCS2011.pdf}
This article deals with several issues which can undermine a scientific result from software. It takes fault rates specifically which result in subtly incorrect results from scientific programs.
\end{refdef}

\begin{refdef}{Monniaux:2008:PVF:1353445.1353446}{a12-monniaux.pdf}
A deep case based analysis of floating point reproducibility problems which can arrise in the analysis of computational code. (a lengthy read)
\end{refdef}

\begin{refdef}{code-complete}{code-complete-2nd-edition-v413hav.pdf}
A large book talking about good coding practices. Recommended by Victoria's Friend
\end{refdef}

\begin{refdef}{ISO-9126}
An ISO standard describing aspects of software quality so that the quality of disparate types of software can be compared on equal footing.
\end{refdef}

\subsection{White Paper References}

\begin{refdef}{MPI-Standard}{}
The article defining 1.0 of the MPI standard.
\end{refdef}

\begin{refdef}{OpenMP-Standard}{}
This paper describes the OpenMP Standard
\end{refdef}

\begin{refdef}{Enzo}{}
This paper describes Enzo and is the official Enzo citation.
\end{refdef}

\begin{refdef}{rockstar}{Behroozi\_2013\_ApJ\_762\_109.pdf}
The rockstar halo finding algorithm.
\end{refdef}

\begin{refdef}{Spack}{a40-gamblin.pdf}
The official citation and introduction to Spack
\end{refdef}

\begin{refdef}{hdf5}{}
The official citation of HDF5
\end{refdef}

\begin{refdef}{yt}{}
The official method paper and citation of YT
\end{refdef}

\begin{refdef}{reprozip}{p2085-chirigati.pdf}
This is the official paper describing the ReproZip tool
\end{refdef}

\begin{refdef}{reproducible-builds}{}
This is the reproducible-builds.org website. They give information about how to make your software reproducible.
\end{refdef}

\begin{refdef}{sciunits}{1707.05731.pdf}
I need to read this paper.
\end{refdef}

\begin{refdef}{computer-physics-communications}{}
A reference with a link to the Computer Physics Communications Journal
\end{refdef}

\begin{refdef}{darpa-open-catalog}{}
A reference with a link to the DARPA Open Catalog
\end{refdef}

\begin{refdef}{doe-code}{}
A reference with a link to the DOE code Catalog
\end{refdef}

\begin{refdef}{elsevier-mendeley-computer-physics-communications}{}
A reference with a link to the mendeley Computer Physics Communications repository
\end{refdef}

\begin{refdef}{blame-analysis}{blame-analysis.pdf}
This paper describes the BLAME Analysis tool which examines a program's instructions and determines which operations can be floating point and which can be double. It runs once and is faster than other tools such as 'Precimonious' which was mentioned. \readmore
\end{refdef}

\begin{refdef}{mpfun}{mpfun2015.pdf}
A paper describing the mpfun tool which is used to provide thread-safe arbitrary precision arithmetic.
\end{refdef}

\subsection{Unassigned}


\begin{refdef}{Czech035360}{035360.full.pdf}
This paper discusses some of the problems with philogenetic tree programs. they had a hard time reproducing published trees. \categorize
\end{refdef}

\begin{refdef}{leshatton-full-repro}{1608.06897.pdf}
An interesting paper by Les Hatton talking about full reproducibilty in biology. \Read \categorize
\end{refdef}

\begin{refdef}{AGORA-II}{1610.03066.pdf}
An extensive test of reproducibility of astrophysical codes across code types. \categorize
\end{refdef}

\begin{refdef}{Stodden1240}{1240.full.pdf}
\Read \categorize \complete
\end{refdef}

\begin{refdef}{stodden-legal}{Stodden\_chapter.pdf}
What computational scientists need to know about intellectual property law: A primer \Read \categorize
\end{refdef}

\begin{refdef}{clusterjob}{osbg-MDS2016.pdf}
THE CLUSTERJOB PAPER \categorize \complete
\end{refdef}

\begin{refdef}{doi:10.1001/jama.294.2.218}{JOC50060.pdf}
A great paper describing replication outcomes for clinical trials \categorize
\end{refdef}

\begin{refdef}{Collberg:2016:RCS:2897191.2812803}{p62-collberg.pdf}
A nice paper about Repeatability in Computer systems research \Read \categorize
\end{refdef}

\begin{refdef}{10.1371/journal.pmed.0020124}{journal.pmed.0020124.PDF}
A great article explaining why most published research findings are false. This article discusses some of the career pressures affecting scientist's decisions. \categorize
\end{refdef}

\begin{refdef}{aac4716}{aac4716.full.pdf}
An article talking about estimating the reproducibility of psychological science \Read \categorize
\end{refdef}

\begin{refdef}{Begley2012}{483531a.pdf}
An article talking about the need to increase the quality of pre-clinical research to increase the effectiveness of cancer studies and getting working treatments from them. \Read \categorize
\end{refdef}

\begin{refdef}{Baker2016}{533452a.pdf}
An article discussing survey responses from scientists asking about reproducibility in their fields. \Read \categorize
\end{refdef}

\begin{refdef}{Begley116}{116.full.pdf}
An article discussing the root causes of the reproducibility problem. \Read \categorize
\end{refdef}

\begin{refdef}{stodden-computational-science-talk}{Science20July2009VictoriaStodden.pdf}
A talk by V.S. about how computation is affecting the scientific method. \categorize
\end{refdef}

\begin{refdef}{acm-badging}{}
A website describing the ACM badging policy. Provides the definitions for Reproducibility terms \categorize
\end{refdef}

\begin{refdef}{Buckheit1995}{10.1007\%2F978-1-4612-2544-7.pdf}
A paper which originates the term `really reproducible research'. It's also about the wavelab matlab software collection. \Read \categorize
\end{refdef}

\begin{refdef}{claerbout-reproducibility-website}{}
A website by Claerbout himself discussion his history with reproducible research. \Read \categorize
\end{refdef}

\begin{refdef}{neuromorphic-chips-webarticle}{}
A website describing neuromorphic chips and how they have applications for deep learning. \Read \categorize
\end{refdef}

\begin{refdef}{King95}{replication.pdf}
A nice article V.S. Recommended which details various issues faced by researchers in empirical political sciences to replicate works by other authors. \Read \categorize
\end{refdef}

\begin{refdef}{elec-doc-res-new-meaning}{}
The original wavelab article about reproducible research. Lays the groundwork for Claerbout's wavelab plan. \Read \categorize
\end{refdef}

\begin{refdef}{doi:10.1109/MCSE.2009.14}{}
Another clarbout article about reproducibility. \Read \categorize
\end{refdef}

\begin{refdef}{ThreeDreams}{ThreeDreams.pdf}
An Article by Donoho describing three dream applications of verifiable computational results. Similar to my Three Methods. \Read \categorize
\end{refdef}

\begin{refdef}{TranslationOpenMPOpenACC}{TranslationOpenMPOpenACC.pdf}
An article describing how to translate between OpenMP and OpenACC. What is missing, and lessons learned. Not exactly portability.. More like Translation. \Read \categorize
\end{refdef}

\begin{refdef}{ProgressIn10Years}{ProgressIn10Years.pdf}
This article contains predictions for where technology and the community will be in 10 years time. Interestingly, it seems like fusion. We're still 10 years away from their predictions. \Read \categorize
\end{refdef}

\begin{refdef}{computational-meta-data}{computational-meta-data.pdf}
This describes several workflow and metadata analysis tools for work provenance. Why-Diff, YesWorkflow, NoWorkflow \Read \categorize
\end{refdef}

\begin{refdef}{FRAPpuccino}{hotcloud17-paper-han.pdf}
A paper describing the meta-workflow analysis software FRAPpuccino. \Read \categorize
\end{refdef}

\begin{refdef}{doi:10.1080/01621459.1972.10481279}{}
An old paper describing the Wilcoxon statistical test among others. The paper isn't online, you have to order it. \categorize
\end{refdef}

\begin{refdef}{10.2307/2984263}{}
An old paper describing Pearson's Chi-squared test for count data. The paper is online, but you have to pay for it. \categorize
\end{refdef}

\begin{refdef}{R-wilcoxon-test}{}
Implementation of the wilcoxon test in R. \categorize
\end{refdef}

\begin{refdef}{R-pearson-chisquare}{}
Implementation of the pearson chisquared test in R. \categorize
\end{refdef}

\begin{refdef}{stodden-reproducibility-scientific-method}{SSRN-id1550193.pdf}
A discussion from Victoria about reproducibility and the computational sciences. \Read \categorize
\end{refdef}

\begin{refdef}{taufer-sc-reproducibility}{}
A reference Victoria insisted on having in the SC17 poster. \Read \categorize
\end{refdef}

%\bibliography{main}
%\bibliographystyle{ieeetranthesis}
\printbibliography[heading=bibintoc]

\printindex

\printglossaries

\end{document}
